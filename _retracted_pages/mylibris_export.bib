@article{wuytsobservingvariance,
author = {Wuyts, C and Loosveldt, G},
journal = {Survey Research Methods},
number = {2},
pages = {147--163},
publisher = {European Survey Research Association},
title = {Observing Interviewer Performance in Slices or by Traces: A Comparison of Methods to Predict Interviewers’ Individual Contributions to Interviewer Variance},
volume = {16},
year = {},
doi = {10.18148/srm/2022.v16i2.7672},
issn = {1864-3361},
keyword = {Interviewer effects},
keyword = {Interviewer monitoring},
keyword = {Survey interviewing},
keyword = {Paradata},
publicationstatus = {online-published},
}
@misc{wuyts2022ancollection,
author = {Wuyts, C},
editor = {Loosveldt, G},
month = {Jun},
title = {An assessment of interviewer characteristics data for explaining interviewer effects on measurement and nonresponse in face-to-face survey data collection},
year = {2022},
abstract = {This dissertation addresses the question of what interviewer characteristics data are useful to collect in order to account for observed interviewer effects in survey data. We conducted a systematic evaluation of the explanatory power of personal interviewer characteristics and interviewer role characteristics, with respect to nonresponse and with respect to survey variables in four rounds of the European Social Survey in Belgium (Rounds 5 to 8). We made use of a rich set of interviewer-level explanatory variables, derived from (a) employee and project records (traditional "found" interviewer characteristics data), (b) specialized interviewer questionnaires, both before and at the end of fieldwork (traditional "designed" interviewer characteristics data), (c) "task as respondent" interviewer data, obtained from the interviewers self-administering the survey questionnaire (non-traditional "found" interviewer characteristics data).
The interviewers had a large influence on response rates and, despite standardized interviewing training and close monitoring, also a certain influence on the measurement of substantive variables in the interviews. We estimated that 25\%-32\% of the variance in establishing contact with households, 6\%\&zwj;-\&zwj;\&zwj;\&zwj;8\% of the variance in obtaining cooperation, and on average 3\% of the variance in survey variables (and much higher levels for some of the survey questions about homosexuality, immigration, and value orientations), was at the interviewer level.
To the extent that interviewers' assigned subsamples are comparable in composition, interviewer variance (resulting from the systematic differences between interviewers) is directly attributable to the interviewers' active and passive influences. The presence of interviewer variance in substantive variables and in various quality indicators suggests that some, more or less stable, characteristics of the interviewers are related to interviewer performance. While a solid body of research on interviewer effects exists, the causes of interviewer variance remain largely unexplained.
 
In order to explain interviewer variance in survey nonresponse and respondents' answers to survey questions, we estimated a series of multilevel regression models, with measurements at the respondent level nested within interviewers, and with different (sets of) explanatory variables at the interviewer level.
We used a uniform modeling approach and, in the main body of this dissertation, focused on a set of common variables at the interviewer level that were similarly measured in each of the four rounds of the European Social Survey in Belgium. We were thus able to replicate most of the analysis across the four survey rounds in order to evaluate the reliability of the findings. Few results were found to hold across the four data sets.
We conclude that the explanatory power of most interviewer characteristics, as they are traditionally obtained from employee and projects records, or measured using specialized interviewer questionnaires, is on the whole modest. The most easily available interviewer characteristics, obtained from employee records (interviewer age and gender) and project records (survey-specific experience) were found of little use to explain either interviewer variance in response rates or interviewer variance in survey variables.
Some particular interviewer role characteristics associated with aspects of interviewers' experience and fieldwork expectations did appear to be useful. Interviewers' expected cooperation rate emerged as the key predictor of both contact rates and cooperation rates. Interviewers who expected higher cooperation rates were more successful at obtaining cooperation, as well as equally or more successful at establishing contact with households. By itself, this variable explained between zero and 15\% of the interviewer variance in household contact, and between 12\% and 34\% of the interviewer variance in cooperation. We also observed that the more experienced interviewers (and the interviewers who are concurrently involved in few other survey projects) on average achieved lower contact rates, without adequately compensating by achieving higher cooperation rates. Remarkably, interviewer experience and the expected cooperation rate in some cases also explain modest to large shares of the interviewer variance in survey questions. These two interviewer characteristics may be picking up some relevant aspect of being a professional survey interviewer that is related to interviewers' active influences when administering the questionnaire.
We also tested some model extensions using additional interviewer-level explanatory variables related to the respective interviewer tasks. The Round 7 and Round 8 results demonstrate that interviewers' attitudes towards persuading respondents and internal locus of success attribution may be positively related to interviewers' performance in establishing contact and obtaining cooperation. The Round 7 results provide no evidence that interviewers' self-reported interviewing behavior, training, concurrent survey employment or work enjoyment explain substantive interviewer variance. The interviewers' work motivations, on the other hand, do appear somehow associated with respondents' answers to some survey questions.
We furthermore presented two studies illustrating the use of another type of "found" interviewer characteristics data, obtained from interviewers self-administering the survey questionnaire as part of their preparation for their interviewing work. "Task as respondent" interviewer data is a byproduct of the survey process, from which interviewer-level explanatory variables can be obtained that are closely related to the task of interviewing respondents. A first illustration considered only the formal aspects of "task as respondent" data. We found evidence for some of the hypothesized associations between interviewer and respondent response behavior characteristics, specifically for income item nonresponse, multiple response, and interview speed. A second illustration considered the substantive content of "task as respondent" data. We found strong evidence for the hypothesized association between interviewers' and respondents' specific beliefs and positions (i.e., between interviewers' and respondents' answers to the same survey questions). As illustrated by these two studies, the task as respondent—in which interviewers self-administer the questionnaire—is not only valuable for interviewers to become familiar with the survey instrument but also provides useful information about the interviewers at almost no additional cost. The interviewer characteristics investigated in these two studies are less conventional, but on the whole prove at least as or even more informative to explain interviewer variance in survey variables, than interviewers' sociodemographic characteristics or typical measurements of interviewer role characteristics obtained using specialized interviewer questionnaires.
We argue in favor of further exploring "found" interviewer characteristics data like this, and by extension characteristics obtained from survey paradata like interview timestamps, contact history and assignment data, and transcriptions of audio recorded interviews, all of which may closely capture (past) interviewer performance in the interviewers' different tasks.},
language = {en},
day = {20},
publicationstatus = {published},
}
@techreport{wuyts2022understandingreport,
author = {Wuyts, C and Meeusen, C and Draulans, V},
institution = {},
month = {May},
publisher = {Centre for Sociological Research},
title = {Understanding gender imbalances in STEM fields in Rwanda: Methodological report},
year = {2022},
abstract = {This report provides a description of the project’s survey data collection activities and an overall evaluation of the survey data quality. The survey questionnaire and enumerator manual are included in the appendices for reference.},
confidential = {False},
isbn = {9789067842365},
day = {1},
publicationstatus = {published},
}
@techreport{wuyts2022understandingrwanda,
author = {Wuyts, C and Meeusen, C and Vandevyvere, I and Cyulinyana, MC and Ishimwe, S and Draulans, V},
institution = {},
month = {Mar},
publisher = {Centre for Sociological Research, KU Leuven},
title = {Understanding gender imbalances in STEM fields in Rwanda: A survey of secondary school students in Kayonza District, Rwanda},
year = {2022},
abstract = {This report outlines the main results from a research project investigating gender gaps in secondary school students’ perceptions of STEM in Rwanda. A survey of secondary school students was conducted in Kayonza District in the Eastern province of Rwanda in June 2021. A total of 915 students in grades S1, S3, S6 were randomly selected from a stratified, random sample of twenty schools (a mix of public, government-aided and private schools, serving both urban and rural communities) in Kayonza District. The students completed a survey questionnaire using tablet computers.},
confidential = {False},
isbn = {9789067842358},
keyword = {gender},
keyword = {STEM},
keyword = {Rwanda},
keyword = {secondary education},
keyword = {gender stereotypes},
day = {18},
publicationstatus = {published},
}
@article{wuyts2020measurementperformance,
author = {Wuyts, C and Loosveldt, G},
journal = {Journal Of Official Statistics},
month = {Jul},
number = {3},
pages = {561--588},
publisher = {Statistics Sweden},
title = {Measurement of interviewer workload within the survey and an exploration of workload effects on interviewers’ field efforts and performance},
volume = {36},
year = {2020},
abstract = {Interviewer characteristics are usually assumed fixed over the fieldwork period. The number of sample units that require the interviewers’ attention, however, can vary strongly over the fieldwork period. Different workload levels produce different constraints on the time interviewers have available to contact, recruit and interview each target respondent, and may also induce different motivational effects on interviewers’ behavior as they perform their different tasks. In this article we show that fine-grained, time-varying operationalizations of project-specific workload can be useful to explain differences in interviewers’ field efforts and achieved response outcomes over the fieldwork period. We derive project-specific workload for each interviewer on each day of fieldwork in two rounds of the European Social Survey in Belgium from contact history and assignment paradata. Project-specific workload is measured as (1) the number of sample units which have been and remain assigned on any day t (assigned case workload), and (2) the number of sample units for which interviewer activity has started and not yet ceased on any day t (active case workload). Capturing temporal variation in interviewers’ workloads in a direct way, the time-varying operationalizations, are better predictors than are the interviewer-level operationalizations of typical (active or potential) workload that are derived from them, as well as the traditional total-count workload operationalization.},
doi = {10.2478/jos-2020-0029},
issn = {0282-423X},
day = {24},
publicationstatus = {published},
}
@article{peetersassessingnonrespondents,
author = {Peeters, L and De Coninck, D and Wuyts, C and Loosveldt, G},
journal = {Journal Of Official Statistics},
number = {3},
pages = {589--607},
publisher = {Statistics Sweden},
title = {Assessing interviewer performance in approaching reissued initial nonrespondents},
volume = {36},
year = {},
doi = {10.2478/jos-2020-0030},
issn = {0282-423X},
publicationstatus = {online-published},
}
@incollection{loosveldt2020arespondents,
address = {New York, NY},
author = {Loosveldt, G and Wuyts, C},
booktitle = {Interviewer Effects from a Total Survey Error Perspective},
editor = {Olson, K and Smyth, JD and Dykema, J and Holbrook, AL and Kreuter, F and West, BT},
number = {22},
pages = {311--322},
publisher = {Chapman and Hall/CRC},
title = {A Comparison of Different Approaches to Examining Whether Interviewer Effects Tend to Vary Across Different Subgroups of Respondents},
year = {2020},
doi = {10.1201/9781003020219},
isbn = {9781003020219},
publicationstatus = {published},
}
@misc{wuyts2019interviewcase,
author = {Wuyts, C and Loosveldt, G},
month = {Jul},
organization = {Zagreb},
title = {Interview speed patterns versus deviating behaviors observed in audio-recorded interviews for (early) identification of field interviewers' harmful interviewing practice: A test case},
year = {2019},
startyear = {2019},
startmonth = {Jul},
startday = {15},
finishyear = {2019},
finishmonth = {Jul},
finishday = {19},
conference = {ESRA},
day = {16},
publicationstatus = {published},
}
@misc{loosveldt2019comparisoneffects,
author = {Loosveldt, G and Wuyts, C},
month = {Feb},
organization = {University of Nebraska-Lincoln},
title = {Comparison of Different Approaches to Evaluate and Explain Interviewer Effects},
year = {2019},
abstract = {Within survey methodology it is common knowledge that interviewers in face-to-face or telephone interviews can have undesirable effects on the obtained answers. These effects can be created in an active way by, for example, asking suggestive questions or they can be obtained in a passive way as a consequence of certain interviewer characteristics eliciting socially desirable answers. These active and passive effects may differ from interviewer to interviewer. These differences between interviewers in systematic effects create additional variance in the data. The proportion of variance in a (substantive) variable that can be explained by the interviewers is the ‘so called’ between-interviewer variance. It is clear that high between-interviewer variance results in a negative assessment of data quality. Notice that not all types of interviewer effects (e.g. ‘pure’ interviewer bias) can be evaluated by means of the analysis of interviewer variance.

A frequently used measure for the evaluation of interviewer variance is the intra class correlation coefficient (ICC). This coefficient expresses the homogeneity of the obtained answers within the interviewers compared with the heterogeneity of the answers between the interviewers. To calculate the within and the between variance components it is important to take into account the two-level hierarchical data structure in which respondents are nested within the interviewers. A two-level random intercept model with no independent variables is generally the starting point for such an analysis. The model provides estimates of the within and between interviewer variance used to calculate the basic value of the ICC. The basic model can be elaborated by interviewer characteristics (e.g. experience, workload, gender, ...) at the interviewer level and respondent characteristics at the respondent level. With the interviewer characteristics one can try to explain the between interviewer variance. If these characteristics partly explain this variance, they give some insight into the mechanism behind the interviewer's effects.

In contrast, the evaluation of the impact of respondent characteristics (and characteristics of the interview situation) specified at the respondent level is less obvious. With respondent characteristics one tries to explain the variance of the substantive dependent variable of the model. But in the context of the evaluation of interviewer variance, respondent characteristics are also specified in the model to control for differences between interviewers in the composition of the respondent groups. The impact of the interviewers are evaluated after respondent characteristics explained part of the variance in the dependent variable. This means that respondent characteristics are used to explain the variance in the substantive dependent variable and that interviewer effects express the variability between interviewers after controlling for these respondent characteristics. Such models do not assess the effect of respondent characteristics on interviewer effects. In fact, the relationship between the respondent characteristics and the interviewer effects is not specified in the model. However it is reasonable to assume that some respondents are more sensitive to interviewer effects and that in some respondent groups the ICCs are higher. So the specification of the basic multi-level model does not really allow to investigate the relationship between certain respondent characteristics and the extent to which these characteristics influence interviewer effects. In this paper, various alternative specifications of the basic model in which this relationship is explicitly specified will be explored and compared with each other.},
startyear = {2019},
startmonth = {Feb},
startday = {26},
finishyear = {2019},
finishmonth = {Feb},
finishday = {28},
conference = {Interviewers and Their Effects from a Total Survey Error Perspective Workshop},
day = {26},
publicationstatus = {published},
}
@misc{wuyts2018interviewersperformance,
author = {Wuyts, C and Loosveldt, G},
month = {Aug},
organization = {Budapest},
title = {Interviewers’ within-survey workload: Measurement and association with task efforts and performance},
year = {2018},
abstract = {The concept of “interviewer burden” suggests that if interviewers experience their tasks as more burdensome (e.g., because of a heavy workload, poor questionnaire design, long interviews, difficult to interview respondents) they adjust their behavior, taking shortcuts in order to reduce the expended time and effort on the survey (“interviewer satisficing”). Applied to face-to-face interviewers’ activities during the contact procedure, this would imply that interviewers with a high burden may be less willing to make additional visits, may give up on difficult samples units prematurely, and may push for a quick decision instead of maintaining the interaction in a single or over multiple visits. Such interviewer satisficing behaviors in the contact procedure harm the effectiveness and efficiency of the fieldwork process, putting additional pressure on the quality-cost trade-off.
In this paper we focus on one aspect of interviewer burden: the workload within the survey, which varies over the fieldwork period. We assess the effect of this within-survey workload, on the outcomes of the contact process in the European Social Survey in Belgium.
Call history and assignment paradata allow the construction of more fine-grained measurements of interviewer workload over the fieldwork period than traditionally used. We will derive within-survey workload as a time-varying interviewer characteristic, measured as (1) the number of sample units for which interviewer activity has started and not yet ceased on any day t, and (2) the number of sample units for which interviewer activity is possible on any day t. Such operationalizations capture changes in the interviewers’ workloads as the fieldwork progresses.},
startyear = {2018},
startmonth = {Aug},
startday = {22},
finishyear = {2018},
finishmonth = {Aug},
finishday = {24},
conference = {International Workshop on Household Survey Nonresponse },
day = {22},
publicationstatus = {published},
}
@misc{wuyts2018interviewersperformance,
author = {Wuyts, C and Loosveldt, G},
month = {Aug},
organization = {Vancouver},
title = {Interviewers’ within-survey workload: Measurement and association with task effort and performance},
year = {2018},
startyear = {2018},
startmonth = {Jul},
startday = {28},
finishyear = {2018},
finishmonth = {Aug},
finishday = {2},
keyword = {interviewer workload},
keyword = {task performance},
keyword = {interview speed},
keyword = {survey nonresponse},
keyword = {European Social Survey},
conference = {Joint Statistical Meetings},
day = {2},
publicationstatus = {published},
}
@misc{vandenplas2018timestampsparadata,
author = {Vandenplas, C and Loosveldt, G and Wuyts, C},
month = {Jan},
title = {Timestamps and other paradata},
year = {2018},
startyear = {2018},
startmonth = {Jan},
startday = {26},
finishyear = {2018},
finishmonth = {Jan},
finishday = {26},
language = {en},
conference = {Method advisory board -ESS },
publicationstatus = {published},
}
@article{loosveldt2018interviewerestimates,
author = {Loosveldt, G and Wuyts, C and Beullens, K},
journal = {QUALITY ASSURANCE IN EDUCATION},
month = {Jan},
number = {2},
pages = {227--242},
publisher = {EMERALD GROUP PUBLISHING LTD},
title = {Interviewer variance and its effects on estimates},
url = {http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2\&SrcApp=PARTNER_APP\&SrcAuth=LinksAMR\&KeyUT=WOS:000432404800007\&DestLinkType=FullRecord\&DestApp=ALL_WOS\&UsrCustomerID=ef845e08c439e550330acc77c7d2d848},
volume = {26},
year = {2018},
doi = {10.1108/QAE-06-2017-0030},
issn = {0968-4883},
eissn = {1758-7662},
language = {English},
day = {1},
publicationstatus = {published},
}
@techreport{wuyts2018europeancollection,
author = {Wuyts, C and Jacobs, L and De Coninck, D and Italiano, P and Loosveldt, G},
institution = {Leuven},
journal = {Research report Survey Methodology},
note = {This report provides both a description and an evaluation of the data collection activities in the context of the eight round of the European Social Survey (ESS) in Belgium (2016-2017). It covers the preparatory work (January to August 2016), the actual fieldwork (September 2016 to January 2017), the data finalization (February to July 2017), and presents the results of the data collection evaluation.},
number = {CeSO/SM/2018-1},
publisher = {Centre for Sociological Research},
title = {European Social Survey Round 8 - Belgium: Process evaluation for the data collection},
year = {2018},
confidential = {False},
isbn = {9789067842099},
keyword = {European Social Survey},
publicationstatus = {published},
}
@techreport{laura2017de2016,
author = {Laura, J and Wuyts, C and Loosveldt, G},
institution = {Leuven},
month = {Nov},
note = {In deze bijdrage wordt, op basis van een analyse van de Belgische gegevens van de European Social Survey (ESS) van 2002 tot 2016 de houding van de Belgische respondenten over vluchtelingen en de evolutie ervan nagegaan. We plaatsen de resultaten ook in Europees perspectief. De voornaamste doelstelling is, om op basis van representatieve en objectieve gegevens afkomstig van de ESS, met dit rapport een bijdrage te leveren aan het debat over de publieke opinie over vluchtelingen via een inzicht te bieden in de trends en patronen. Dit rapport biedt een beschrijvende presentatie van de resultaten voor België met een aanzet om een aantal groepen te identificeren die verschillen in hun visie op vluchtelingen. Het wil een antwoord bieden op de vraag hoe de Belgen staan tegenover vluchtelingen en diens rechten.},
publisher = {Centre for Survey Methodology},
title = {De visie van de Belg op vluchtelingen: Een overzicht van de resultaten van de European Social Survey (ESS) 2016},
year = {2017},
keyword = {vluchtelingen},
keyword = {migratie},
keyword = {European Social Survey},
publicationstatus = {published},
}
@techreport{jacobs2017de2016,
author = {Jacobs, L and Wuyts, C and Loosveldt, G},
institution = {Leuven},
month = {Nov},
note = {Klimaatverandering betreft een thema dat vele mensen beroert en menig politieke debatten voedt, zoals discussies over het al dan niet opwekken van hernieuwbare energie, het belasten van fossiele brandstoffen, het subsidiëren van zonne- en windenergie, het sluiten van kerncentrales, het invoeren van emissiereducties, en het verlagen van de ecologische voetafdruk. In dit rapport gaan we, op basis van een analyse van de Belgische gegevens van de European Social Survey (ESS) voor 2016 de houding van de Belgen tegenover klimaat en klimaatverandering na. De centrale doelstelling van het rapport bestaat erin om de belangrijkste patronen in de publieke opinie over klimaat te beschrijven op basis van een bevraging van een representatieve steekproef uit de Belgische bevolking.},
publisher = {Centre for Survey Methodology},
title = {De visie van de Belg op klimaatverandering: Een overzicht van de resultaten van de European Social Survey (ESS) 2016},
year = {2017},
keyword = {klimaatverandering},
keyword = {European Social Survey},
publicationstatus = {published},
}
@techreport{jacobs2017public20022014,
author = {Jacobs, L and Wuyts, C and Loosveldt, G},
institution = {},
month = {Sep},
title = {Public opinion about migration in Belgium: Continuity or change? (2002–2014)},
year = {2017},
abstract = {An overview of the results of the European Social Survey (ESS) in Belgium about public opinion on migration (2002-2014)},
keyword = {Migration},
keyword = {ESS},
keyword = {Public opinion},
keyword = {Survey methodology},
keyword = {KUL-CoE-CAS},
publicationstatus = {published},
}
@article{wuyts2017explainingdata,
author = {Wuyts, C and Vercruyssen, A and Loosveldt, G},
journal = {Statistical Journal of the IAOS },
month = {Aug},
number = {3},
pages = {645--659},
publisher = {IOS Press},
title = {Explaining survey nonresponse in the ESS in Belgium using municipality-level administrative registry data},
volume = {33},
year = {2017},
abstract = {Suitable auxiliary data is important in order to assess the potentially detrimental effects of nonresponse on survey estimates. Whereas sufficient individual-level auxiliary data is rarely available, aggregated data is often quite readily accessible. We investigate whether municipality-level data from official administrative registries is useful to explain and predict individuals’ survey response outcomes in two rounds of the European Social Survey (ESS) in Belgium. This study was prompted by the recent publication of the 2011 Belgian Census. This is the first Belgian census produced by linking various national administrative databases instead of a nationwide survey. It offers free and easy access to a broad range of data at the municipality level. We find no consistent results in the two rounds of the ESS, and the overall usefulness of aggregated data appears limited. Individual-level data available from other auxiliary sources is more strongly and more consistently related to survey response outcomes. Nonresponse analyses in the ESS and other surveys would benefit from access to individual-level administrative registry data, but as this is usually restricted, alternative auxiliary data sources such as interviewer observations will need to suffice.},
doi = {10.3233/SJI-160288},
issn = {1874-7655},
eissn = {1875-9254},
keyword = {auxiliary data},
keyword = {nonresponse},
keyword = {census},
keyword = {European Social Survey},
language = {en},
publicationstatus = {published},
}
@techreport{jacobs2017devlaanderen,
author = {Jacobs, L and Wuyts, C and Loosveldt, G},
institution = {Leuven},
month = {Jun},
publisher = {Centre for Survey Methodology},
title = {De visie van de Belg op migratie: Stabiliteit of verandering? (2002 – 2014) Een overzicht van de resultaten van de European Social Survey (ESS) of het Europees Sociaal Onderzoek in Vlaanderen},
year = {2017},
abstract = {De European Social Survey (ESS) wordt sinds 2002 elke twee jaar georganiseerd in een groot aantal Europese landen. België heeft deelgenomen aan alle ESS rondes. 
Het ESS onderzoek in België wordt voorbereid, uitgevoerd en gevaloriseerd door het Centre for Survey Methodology (KU Leuven) voor Vlaanderen en het Centre d’Etude de l’Opinion (Université Liège) voor Wallonië. 
De ESS vragenlijst bestaat uit een aantal vragen die in elke ronde worden gesteld en een aantal vragen rond een specifiek thema. In 2002 en 2014 werden de burgers in detail bevraagd over migratie. In dit rapport geven we een overzicht van de belangrijkste resultaten voor België wat betreft de houding tegenover migratie.},
keyword = {_none},
publicationstatus = {published},
}
@article{vercruyssen2017thebelgium,
author = {Vercruyssen, A and Wuyts, C and Loosveldt, G},
journal = {Social Science Research },
month = {Mar},
pages = {229--238},
title = {The effect of sociodemographic (mis)match between interviewers and respondents on unit and item nonresponse in Belgium},
volume = {67},
year = {2017},
abstract = {Interviewer characteristics affect nonresponse and measurement errors in face-to-face surveys. Some studies have shown that mismatched sociodemographic characteristics – for example gender – affect people’s behaviour when interacting with an interviewer at the door and during the survey interview, resulting in more nonresponse. We investigate the effect of sociodemographic (mis)matching on nonresponse in two successive rounds of the European Social Survey in Belgium. As such, we replicate the analyses of the effect of (mis)matching gender and age on unit nonresponse on the one hand, and of gender, age and education level(mis)matching on item nonresponse on the other hand. Recurring effects of sociodemographic (mis)match are found for both unit and item nonresponse.},
doi = {10.1016/j.ssresearch.2017.02.007},
issn = {0049-089X},
eissn = {1096-0317},
keyword = {interviewer characteristics},
keyword = {interviewer effects},
keyword = {unit nonresponse},
keyword = {item nonresponse},
keyword = {sociodemographic matching},
keyword = {European Social Survey},
language = {en},
day = {8},
publicationstatus = {published},
}
@techreport{wuyts2017thebelgium,
author = {Wuyts, C and Loosveldt, G},
institution = {Leuven},
journal = {Research Report Survey Methodology},
note = {This report describes the interviewer data collected in round 5 to 7 of the European Social Survey (ESS) in Belgium to gain insight into the ESS interviewer capacity and to explain interviewer effects in the ESS data. The collection and study of the interviewer data falls under KPI 7 (‘Special focus: the role of the interviewer in the survey’) of the ESS ESFRI project in Flanders.},
number = {CeSO/ SM /2017-1},
publisher = {Centre for Sociological Research},
title = {The interviewers in the European Social Survey Round 5 to 7 - Belgium},
year = {2017},
confidential = {False},
isbn = {9789067842037},
keyword = {Interviewers},
keyword = {Interviewer characteristics},
keyword = {European Social Survey},
publicationstatus = {published},
}
@techreport{wuyts2017samplingbelgium,
author = {Wuyts, C and Loosveldt, G},
institution = {Leuven},
journal = {Research Report Survey Methodology},
note = {This report describes the sampling procedure for the European Social Survey (ESS) round 8 in Belgium. The activities undertaken to implement the procedure fall under KPI 1 (‘Steekproeftrekking’) of the ESS ESFRI project funded by FWO – Research Foundation Flanders.},
number = {CeSO/SM/2017-3},
publisher = {Centre for Sociological Research},
title = {Sampling for the European Social Survey Round 8 - Belgium},
year = {2017},
confidential = {False},
isbn = {9789067842051},
keyword = {European Social Survey},
language = {en},
publicationstatus = {published},
}
@misc{wuyts2017anboth,
author = {Wuyts, C and Vandenplas, C and Loosveldt, G},
organization = {Lisbon},
title = {An interviewer-oriented analysis of interview speed: Experience, burden, or both?},
year = {2017},
startyear = {2017},
startmonth = {Jul},
startday = {17},
finishyear = {2017},
finishmonth = {Jul},
finishday = {21},
keyword = {interview speed},
keyword = {interviewer experience},
keyword = {interviewer burden},
keyword = {European Social Survey},
language = {en},
conference = {ESRA},
publicationstatus = {published},
}
@article{wuyts2016thequestions,
author = {Wuyts, C and Loosveldt, G},
journal = {Field Methods },
month = {Aug},
number = {2},
pages = {140--153},
title = {The interviewer in the respondent’s shoes: What can we learn from the way interviewers answer survey questions?},
volume = {29},
year = {2016},
abstract = {Previous research shows that interviewers to some extent fail to expend the effort that is needed to collect high-quality survey data. We extend the idea of interviewer satisficing to a related task, in which the interviewers themselves answer survey questions. We hypothesize that interviewers who self-administer the questionnaire in a careless manner, also will not apply themselves fully to the task of administering survey interviews. Based on interviewer and respondent data from the sixth round of the European Social Survey in Belgium, we find support for some of the hypothesized associations between (suboptimal) response characteristics of interviewers in the “task as respondent” and the same (suboptimal) response characteristics recorded for their respondents, specifically with regard to interview speed, multiple response, and item nonresponse to the household income question.},
doi = {10.1177/1525822X16663162},
issn = {1525-822X},
eissn = {1552-3969},
keyword = {Interviewer satisficing},
keyword = {interviewer behavior},
keyword = {European Social Survey},
language = {en},
day = {31},
publicationstatus = {published},
}
@misc{wuyts2016workloadrelatedbelgium,
author = {Wuyts, C and Loosveldt, G},
organization = {Oslo},
title = {Workload-related interviewer characteristics and unit nonresponse in ESS Belgium},
year = {2016},
startyear = {2016},
startmonth = {Aug},
startday = {31},
finishyear = {2016},
finishmonth = {Sep},
finishday = {2},
keyword = {nonresponse},
keyword = {interviewer workload},
keyword = {interviewer time burden},
keyword = {European Social Survey},
language = {en},
conference = {International Workshop on Household Survey Nonresponse},
publicationstatus = {published},
}
@techreport{barbier2016europeancollection,
author = {Barbier, S and Wuyts, C and Italiano, P and Loosveldt, G},
institution = {Leuven},
journal = {Research report Survey Methodology},
note = {This  report  provides  both  a  description  and  an  evaluation  of  the  data  collection  activities  in  the context of the seventh round of the European Social Survey (ESS) in Belgium (2014-2015). It covers the daily activities and decisions taken as part of the preparatory work (January to August 2014), the actual fieldwork (September 2014 to January 2015), and the data finalization (February to July 2015).},
number = {CeSO/SM/2016-1},
publisher = {Centre for Sociological Research},
title = {European Social Survey Round 7 - Belgium: Process evaluation for the data collection},
year = {2016},
confidential = {False},
isbn = {9789067841948},
keyword = {European Social Survey},
publicationstatus = {published},
}
@misc{wuyts2016comparisonthoughts,
author = {Wuyts, C and Barbier, S and Loosveldt, G},
organization = {Lausanne},
title = {Comparison of alcohol consumption in European countries, and some methodological thoughts},
year = {2016},
startyear = {2016},
startmonth = {Jul},
startday = {13},
finishyear = {2016},
finishmonth = {Jul},
finishday = {15},
keyword = {alcohol consumption},
keyword = {interviewer effects},
keyword = {cross-country comparison},
keyword = {European Social Survey},
language = {en},
conference = {ESS Conference},
publicationstatus = {published},
}
@techreport{vercruyssen2016auxiliarydata,
author = {Vercruyssen, A and Wuyts, C and Loosveldt, G},
institution = {Leuven},
journal = {Research Report Survey Methodology},
note = {This research report assesses three sources of freely available auxiliary data from external databases: the national registry and related official administrative databases, the police statistics database, and Google Maps and Street View. Auxiliary data from each source were identified, gathered and linked to survey response outcomes for Round 6 and/or Round 7 of ESS Belgium, fielded in the fall of 2012 and the fall of 2014, respectively.},
number = {CeSO/SM/2016-2},
publisher = {Centre for Sociological Research},
title = {Auxiliary data for the European Social Survey Belgium. A search for easily available and straightforwardly useable external data},
year = {2016},
confidential = {False},
isbn = {9789067841986},
keyword = {European Social Survey},
language = {en},
publicationstatus = {published},
}
@misc{wuyts2015thequestions,
author = {Wuyts, C and Loosveldt, G},
organization = {Reykjavik},
title = {The interviewer in the respondent’s shoes: What can we learn of how interviewers answer survey questions?},
year = {2015},
startyear = {2015},
startmonth = {Jul},
startday = {14},
finishyear = {2015},
finishmonth = {Jul},
finishday = {17},
keyword = {interviewer satisficing},
keyword = {interviewer behavior},
keyword = {task-as-respondent},
keyword = {European Social Survey},
keyword = {_none},
language = {en},
conference = {ESRA},
publicationstatus = {published},
}
@misc{wuyts2015makingdata,
author = {Wuyts, C and Vercruyssen, A and Loosveldt, G},
organization = {Leuven},
title = {Making sense of nonresponse with the newest Belgian census data? A test case on the Belgian ESS6 data},
year = {2015},
abstract = {At the end of 2014, the data of the Census 2011 became available in Belgium. In difference to the previous edition from 2001, the current census results from linking various national administrative databases instead of using a nation-wide survey. This makes the 2011 census a potentially useful source of auxiliary data for Belgian surveys. Even though access to individual-level data is strictly limited, aggregate data on the postcode level are freely available. These data contain information on the municipalities’ socio-demographic composition, employment, education levels, and housing, and supplement the more limited set of annually updated socio-economic characteristics from Statistics Belgium. But does this vast amount of paradata on postcode level enable us to say something about nonresponse in ESS6 or the survey climate in Belgium or specific Belgian municipalities?  We explore to which extent municipality characteristics are predictive of nonresponse patterns (refusal, noncontact, and other nonresponse) and their potential relevance to sample designs of future data collection.},
startyear = {2015},
startmonth = {Sep},
startday = {2},
finishyear = {2015},
finishmonth = {Sep},
finishday = {4},
keyword = {auxiliary data},
keyword = {nonresponse},
keyword = {census},
keyword = {European Social Survey},
language = {en},
conference = {International Workshop on Household Survey Nonresponse },
publicationstatus = {published},
}
@techreport{tirry20141020022012,
author = {Tirry, D and Wuyts, C and Loosveldt, G and Meuleman, B},
institution = {Leuven},
publisher = {Centrum voor Sociologisch Onderzoek},
title = {10 jaar 'European Social Survey'. Enkele resultaten van de eerste zes rondes (2002-2012)},
year = {2014},
isbn = {9789067841856},
keyword = {European Social Survey},
keyword = {België},
publicationstatus = {published},
}
